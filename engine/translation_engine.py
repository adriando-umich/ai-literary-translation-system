# engine/translation_engine.py
# Responsibility:
# - Translate text blocks into Vietnamese
# - NO state mutation
# - Model selection explicit
# - Support rolling intra-chapter context (read-only)
# - Fail-loud, debug-first
# Python 3.9 compatible

import os
import time
import json
import re
import random  # <--- TH√äM: ƒê·ªÉ t√≠nh th·ªùi gian ch·ªù ng·∫´u nhi√™n (Jitter)
from typing import Optional, Dict, List
from utils.logger import log

# === THAY ƒê·ªîI: D√πng th∆∞ vi·ªán Google GenAI g·ªëc ƒë·ªÉ ch·ªânh Safety Settings ===
from google import genai
from google.genai import types
from google.genai import errors  # <--- TH√äM: ƒê·ªÉ b·∫Øt l·ªói API ch√≠nh x√°c


# =========================================================
# PRONOUN RULE BUILDER (HARD CONSTRAINT)
# =========================================================
def build_pronoun_rules(characters: list) -> str:
    """
    Build HARD CONSTRAINT rules for Vietnamese 3rd-person pronouns.
    characters: list of character objects with vi_pronoun
    """
    lines = []

    for c in characters:
        name = c.get("name")
        vi = c.get("vi_pronoun", {}).get("default")

        if name and vi:
            lines.append(f'- "{name}" MUST be referred to as "{vi}"')

    if not lines:
        return ""

    return (
            "CHARACTER PRONOUN RULES (ABSOLUTE):\n"
            "- When translating English third-person references "
            "(he / him / his), you MUST use the Vietnamese pronoun specified below.\n"
            "- You MUST NOT vary pronouns for style.\n"
            "- You MUST NOT replace pronouns with character names or descriptions.\n"
            "- You MUST NOT avoid pronouns by repeating names.\n"
            "- Any pronoun violation INVALIDATES the output.\n\n"
            "Pronoun mapping:\n"
            + "\n".join(lines)
            + "\n"
    )


# =========================================================
# ENGINE
# =========================================================
class TranslationEngine:
    def __init__(self):
        """
        Kh·ªüi t·∫°o Engine d√πng Google GenAI SDK (Official)
        L√Ω do: ƒê·ªÉ t·∫Øt b·ªô l·ªçc n·ªôi dung (BLOCK_NONE) tr√°nh l·ªói PROHIBITED_CONTENT
        """
        # 1. C·∫•u h√¨nh Model (Logic Fallback)
        # Model ch√≠nh ∆∞u ti√™n d√πng (R·∫ª/Nhanh)
        self.model_primary = "gemini-2.5-flash-lite"
        # Model fallback n·∫øu model ch√≠nh l·ªói (·ªîn ƒë·ªãnh)
        self.model_fallback = "gemini-2.0-flash"

        # C·∫≠p nh·∫≠t Glossary c≈©ng ∆∞u ti√™n Lite
        self.model_glossary = "gemini-2.5-flash-lite"
        self.max_retries = 5
        self.timeout_sec = 120  # Timeout x·ª≠ l√Ω logic retry

        # 2. L·∫•y API Key
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("‚ùå L·ªñI: Thi·∫øu d√≤ng GOOGLE_API_KEY=... trong file .env")

        # 3. T·∫°o Client Google (Native)
        self.client = genai.Client(api_key=api_key)

    # =========================================================
    # LOW-LEVEL API CALL (REPLACED OPENAI WITH GEMINI NATIVE)
    # =========================================================
    def _call_gemini_native(self, *, prompt: str, model: str) -> str:
        """
        G·ªçi tr·ª±c ti·∫øp Google Gemini v·ªõi c·∫•u h√¨nh t·∫Øt to√†n b·ªô Safety Filter.
        T√≠ch h·ª£p logic x·ª≠ l√Ω l·ªói 429 (Quota) v·ªõi Exponential Backoff.
        """
        # Debug ƒë·ªÉ b·∫°n t·ª± ki·ªÉm tra
        print(f"[DEBUG] Model ID g·ª≠i ƒëi: {model}")

        # --- C·∫§U H√åNH QUAN TR·ªåNG: T·∫ÆT B·ªò L·ªåC ---
        safety_settings = [
            types.SafetySetting(
                category="HARM_CATEGORY_HARASSMENT",
                threshold="BLOCK_NONE",
            ),
            types.SafetySetting(
                category="HARM_CATEGORY_HATE_SPEECH",
                threshold="BLOCK_NONE",
            ),
            types.SafetySetting(
                category="HARM_CATEGORY_SEXUALLY_EXPLICIT",
                threshold="BLOCK_NONE",
            ),
            types.SafetySetting(
                category="HARM_CATEGORY_DANGEROUS_CONTENT",
                threshold="BLOCK_NONE",
            ),
        ]

        # C·∫•u h√¨nh sinh vƒÉn b·∫£n
        generate_config = types.GenerateContentConfig(
            safety_settings=safety_settings,
            temperature=0.3,  # Gi·ªØ m·ª©c th·∫•p ƒë·ªÉ d·ªãch ch√≠nh x√°c
        )

        base_delay = 5  # Gi√¢y ch·ªù c∆° b·∫£n

        for attempt in range(1, self.max_retries + 1):
            try:
                log(f"CALL API attempt {attempt}/{self.max_retries} | model={model}")

                # G·ªåI SDK C·ª¶A GOOGLE
                response = self.client.models.generate_content(
                    model=model,
                    contents=prompt,
                    config=generate_config
                )

                # =========================================================
                # DEBUG LOGIC: LOG CHI TI·∫æT KHI API TR·∫¢ V·ªÄ R·ªñNG
                # =========================================================
                if not response.text:
                    print(f"\n‚ùå [DEBUG ERROR] Chunk g√¢y l·ªói (Attempt {attempt}):")
                    # In snippet ƒë·ªÉ debug
                    print(f"--- INPUT SNIPPET ---\n...{prompt[-300:]}\n---------------------")

                    finish_reason = "Unknown"
                    if response.candidates:
                        c = response.candidates[0]
                        finish_reason = c.finish_reason
                        if hasattr(c, 'safety_ratings'):
                            print(f"‚ö†Ô∏è Safety Ratings: {c.safety_ratings}")

                    # N·∫øu h·∫øt l∆∞·ª£t -> B√°o l·ªói ƒë·ªÉ k√≠ch ho·∫°t Fallback ·ªü t·∫ßng tr√™n
                    if attempt == self.max_retries:
                        raise RuntimeError(f"API tr·∫£ v·ªÅ n·ªôi dung r·ªóng. Reason: {finish_reason}")

                    raise ValueError("Empty response (triggering retry)")
                # =========================================================

                # L·∫§Y TEXT
                text = response.text.strip()
                return text

            # --- X·ª¨ L√ù L·ªñI 429 (QUOTA EXHAUSTED) ---
            except errors.ClientError as e:
                if e.code == 429:
                    if attempt == self.max_retries:
                        log(f"‚ùå API ERROR: 429 Quota exhausted for model {model}.")
                        raise e  # N√©m l·ªói ra ƒë·ªÉ trigger fallback

                    # Exponential Backoff: Ch·ªù l√¢u h∆°n sau m·ªói l·∫ßn l·ªói
                    wait_time = (base_delay * (2 ** (attempt - 1))) + random.uniform(1, 3)
                    print(f"‚ö†Ô∏è [429 Quota] Model {model} b·ªã gi·ªõi h·∫°n. ƒêang ch·ªù {wait_time:.1f}s... (L·∫ßn {attempt})")
                    time.sleep(wait_time)
                else:
                    log(f"API CLIENT ERROR: {e}")
                    if attempt == self.max_retries:
                        raise e
                    time.sleep(2)

            # --- X·ª¨ L√ù L·ªñI KH√ÅC (M·∫°ng, Server 500...) ---
            except Exception as e:
                print(f"[DEBUG] L·ªói th·∫≠t s·ª±: {e}")
                log(f"API ERROR: {e}")
                if attempt == self.max_retries:
                    raise e
                time.sleep(2 * attempt)

        raise RuntimeError("Max retries exceeded")

    # =========================================================
    # COMPATIBILITY LAYER (C·∫¶U N·ªêI CHO MAIN.PY)
    # =========================================================
    def _call_openai(self, *, prompt: str, model: str) -> str:
        """
        H√†m t∆∞∆°ng th√≠ch ng∆∞·ª£c: main.py g·ªçi h√†m n√†y ƒë·ªÉ t·∫°o Glossary.
        Logic: Th·ª≠ Primary (Lite) tr∆∞·ªõc -> L·ªói -> Fallback (Flash 2.0).
        """
        try:
            return self._call_gemini_native(prompt=prompt, model=self.model_primary)
        except Exception as e:
            log(f"‚ö†Ô∏è GLOSSARY PRIMARY FAILED: {e}")
            log(f"üîÑ SWITCHING GLOSSARY TO FALLBACK: {self.model_fallback}")
            return self._call_gemini_native(prompt=prompt, model=self.model_fallback)

    # =========================================================
    # PUBLIC API ‚Äî TRANSLATE CHUNK
    # =========================================================
    def translate_chunk(
            self,
            *,
            en_blocks: List[str],
            glossary_rules: str = "",
            summary: str = "",
            characters: Optional[str] = None,  # JSON STRING from main.py
            intra_chapter_context: Optional[List[str]] = None,
            is_narrative: bool = False,
            chunk_index: Optional[int] = None,
            total_chunks: Optional[int] = None,
    ) -> List[str]:
        """
        Translate a list of English blocks into Vietnamese.
        LOGIC: Th·ª≠ Model Primary -> L·ªói -> Fallback sang Model Secondary.
        """

        kind = "NARRATIVE" if is_narrative else "NON_NARRATIVE"
        N = len(en_blocks)

        chunk_info = (
            f"{chunk_index}/{total_chunks}"
            if chunk_index and total_chunks
            else "?"
        )

        log(
            f"AI TRANSLATE CHUNK | type={kind} | "
            f"chunk={chunk_info} | blocks={N} | "
            f"intra_ctx_blocks={len(intra_chapter_context or [])}"
        )

        numbered_blocks: List[str] = []
        for i, block in enumerate(en_blocks, start=1):
            numbered_blocks.append(f"[{i}] {block}")

        numbered_text = "\n".join(numbered_blocks)

        intra_context_text = ""
        if intra_chapter_context:
            trimmed_ctx = intra_chapter_context[-200:]
            intra_context_text = (
                    "INTRA-CHAPTER CONTEXT (REFERENCE ONLY):\n"
                    "The following text is from PREVIOUS translated blocks.\n"
                    "Use ONLY for tone, terminology, pronouns, and flow.\n"
                    "DO NOT translate, repeat, or continue it.\n\n"
                    + "\n".join(trimmed_ctx)
                    + "\n\n"
            )

        if is_narrative:
            role = "You are a professional literary translator."
            extra_rules = ""
        else:
            role = "You are a translation engine."
            extra_rules = (
                "This is NON-NARRATIVE content.\n"
                "Translate literally.\n"
                "Do NOT embellish or interpret.\n"
            )

        pronoun_rules = ""
        if is_narrative and characters:
            try:
                character_list = json.loads(characters)
                pronoun_rules = build_pronoun_rules(character_list)
            except Exception:
                raise RuntimeError("INVALID CHARACTER CONTEXT: cannot parse pronoun rules")

        prompt = f"""
{role}

TARGET LANGUAGE:
Vietnamese.

You MUST translate ALL content into Vietnamese.

{extra_rules}

{glossary_rules}

{pronoun_rules}

GLOBAL CONTEXT (if provided):
Summary:
{summary}

{intra_context_text}

STRICT RULES (MANDATORY ‚Äî VIOLATION = INVALID OUTPUT):

FORMAT RULES:
- Input text contains NUMBERED blocks.
- EACH numbered block MUST produce EXACTLY ONE output line.
- EVEN IF a block is very short, it MUST still have its own output line.
- DO NOT merge, combine, summarize, or infer across blocks.
- DO NOT split blocks.
- DO NOT add or remove lines.
- Output MUST contain EXACTLY {N} lines.
- Each output line MUST start with the SAME block number as input.

NO META OUTPUT (ABSOLUTE):
- You MUST output ONLY translation lines.
- You MUST NOT add notes, explanations, confirmations, or commentary.
- You MUST NOT include text such as:
  "Note:", "Explanation:", "Here is", "I have", "I followed", or similar.

- ANY line that does NOT start with a block number [i] is INVALID.


INPUT:
{numbered_text}

OUTPUT FORMAT (EXACT):
[1] <Vietnamese translation>
[2] <Vietnamese translation>
...
""".strip()

        vi_text = ""
        try:
            vi_text = self._call_gemini_native(prompt=prompt, model=self.model_primary)
        except Exception as e:
            log(f"‚ö†Ô∏è PRIMARY MODEL ({self.model_primary}) FAILED: {e}")
            log(f"üîÑ SWITCHING TO FALLBACK MODEL: {self.model_fallback}")
            try:
                vi_text = self._call_gemini_native(prompt=prompt, model=self.model_fallback)
            except Exception as e_fallback:
                log(f"‚ùå FALLBACK MODEL FAILED: {e_fallback}")
                raise e_fallback

        pattern = re.compile(r"\[(\d+)\]\s*(.*?)\s*(?=\[\d+\]|$)", re.S)
        matches = pattern.findall(vi_text)

        if not matches:
            log("=== RAW MODEL OUTPUT BEGIN ===")
            log(vi_text)
            log("=== RAW MODEL OUTPUT END ===")
            raise RuntimeError("INVALID OUTPUT: no indexed blocks found")

        vi_blocks: List[str] = []
        for idx_str, content in matches:
            vi_blocks.append(content.strip())

        if len(vi_blocks) != len(en_blocks):
            log("=== RAW MODEL OUTPUT BEGIN ===")
            log(vi_text)
            log("=== RAW MODEL OUTPUT END ===")
            raise RuntimeError(f"BLOCK COUNT MISMATCH: {len(en_blocks)} EN vs {len(vi_blocks)} VI")

        log(f"AI TRANSLATE CHUNK | success | type={kind} | blocks={len(vi_blocks)}")
        return vi_blocks